{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d99168e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0cd109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from scipy import stats\n",
    "from scipy.linalg import solveh_banded\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import OrderedDict\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy\n",
    "from bioinfokit.analys import stat\n",
    "import scipy.stats as stats\n",
    "import seaborn as sn\n",
    "from statannot import add_stat_annotation\n",
    "from scipy.signal import savgol_filter \n",
    "from itertools import chain\n",
    "from minisom import MiniSom\n",
    "import matplotlib\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.patches import RegularPolygon \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac334fc3",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3137d",
   "metadata": {},
   "source": [
    "Folder inputs\n",
    "\n",
    "there are 3 different formattings:\n",
    "\n",
    "1) r'/...'\n",
    "2) r'C:\\...'\n",
    "3) 'C:\\\\...'\n",
    "\n",
    "But basically just copy past the directory from your main folder. Since I am using ubuntu it comes out as the 1) option. On windows it should be option 2)\n",
    "\n",
    "The data should be organized in a hierarchical way, ie, samples > replicates > single spectra.txt (broken from a Raman map using the Renishaw software)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4a71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainfolders = [\n",
    "        r'/home/paulo/Documents/PhD/own papers/mike paper/all data/Corynebacterium glutamicum'\n",
    "        ,\n",
    "        r'/home/paulo/Documents/PhD/own papers/mike paper/all data/Mycobacterium bovis BCG'\n",
    "        ,\n",
    "        r'/home/paulo/Documents/PhD/own papers/mike paper/all data/Rhodococcus erythropolis'\n",
    "        ]\n",
    "\n",
    "if all(len(a.split('\\\\'))>1 for a in mainfolders):\n",
    "    [('/').join(a.split('\\\\')) for a in mainfolders]\n",
    "    \n",
    "#colour setup (still needs to be coded)\n",
    "NUM_COLORS = len(mainfolders)  \n",
    "cmaps = plt.get_cmap('gist_rainbow')\n",
    "colours = [cmaps(1.*i/NUM_COLORS) for i in range(NUM_COLORS)]\n",
    "\n",
    "#if you want a specific colour scheme write it here and comment the previous lines\n",
    "# check the colour list in https://matplotlib.org/2.2.0/gallery/color/named_colors.html\n",
    "#colours = []\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colours) \n",
    "\n",
    "#the clean parameter is related to a z-score test sigma value. A value of 3 is enought to clean up the data\n",
    "# if the data values are outliers they will be removed.\n",
    "clean = 3\n",
    "\n",
    "#save folder (to save the excel sheet related to the peak finding script)\n",
    "savefolder = r'/home/paulo/Documents/PhD/own papers/mike paper/all data/peaks/'\n",
    "\n",
    "#SOM section insert the number of hexagon sides that you want (square shape)\n",
    "neuron = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae09dba",
   "metadata": {},
   "source": [
    "Plot setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8d06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'Arial',\n",
    "        'size'   : 16}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [9.0, 9.0/1.618]\n",
    "mpl.rcParams['figure.dpi'] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07c9d4",
   "metadata": {},
   "source": [
    "# Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87815b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From MatrixExp\n",
    "def matrix_exp_eigen(U, s, t, x):\n",
    "    exp_diag = np.diag(np.exp(s * t), 0)\n",
    "    return U.dot(exp_diag.dot(U.transpose().dot(x))) \n",
    "\n",
    "# From LineLaplacianBuilder\n",
    "def get_line_laplacian_eigen(n):\n",
    "    assert n > 1\n",
    "    eigen_vectors = np.zeros([n, n])\n",
    "    eigen_values = np.zeros([n])\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "        theta = np.pi * (j - 1) / (2 * n)\n",
    "        sin = np.sin(theta)\n",
    "        eigen_values[j - 1] = 4 * sin * sin\n",
    "        if j == 0:\n",
    "            sqrt = 1 / np.sqrt(n)\n",
    "            for i in range(1, n + 1):\n",
    "                eigen_vectors[i - 1, j - 1] = sqrt\n",
    "        else:\n",
    "            for i in range(1, n + 1):\n",
    "                theta = (np.pi * (i - 0.5) * (j - 1)) / n\n",
    "                math_sqrt = np.sqrt(2.0 / n)\n",
    "                eigen_vectors[i - 1, j - 1] = math_sqrt * np.cos(theta)\n",
    "    return eigen_vectors, eigen_values\n",
    "\n",
    "def smooth2(t, signal):\n",
    "    dim = signal.shape[0]\n",
    "    U, s = get_line_laplacian_eigen(dim)\n",
    "    return matrix_exp_eigen(U, -s, t, signal)\n",
    "\n",
    "\n",
    "def als_baseline(intensities, asymmetry_param=0.05, smoothness_param=1e6,\n",
    "                 max_iters=10, conv_thresh=1e-5, verbose=False):\n",
    "  '''Computes the asymmetric least squares baseline.\n",
    "  * http://www.science.uva.nl/~hboelens/publications/draftpub/Eilers_2005.pdf\n",
    "  smoothness_param: Relative importance of smoothness of the predicted response.\n",
    "  asymmetry_param (p): if y > z, w = p, otherwise w = 1-p.\n",
    "                       Setting p=1 is effectively a hinge loss.\n",
    "  '''\n",
    "  smoother = WhittakerSmoother(intensities, smoothness_param, deriv_order=2)\n",
    "  # Rename p for concision.\n",
    "  p = asymmetry_param\n",
    "  # Initialize weights.\n",
    "  w = np.ones(intensities.shape[0])\n",
    "  for i in range(max_iters):\n",
    "    z = smoother.smooth(w)\n",
    "    mask = intensities > z\n",
    "    new_w = p*mask + (1-p)*(~mask)\n",
    "    conv = np.linalg.norm(new_w - w)\n",
    "    if verbose:\n",
    "      print (i+1, conv)\n",
    "    if conv < conv_thresh:\n",
    "      break\n",
    "    w = new_w\n",
    "  else:\n",
    "    print ('ALS did not converge in %d iterations' % max_iters)\n",
    "  return z\n",
    "\n",
    "\n",
    "class WhittakerSmoother(object):\n",
    "  def __init__(self, signal, smoothness_param, deriv_order=1):\n",
    "    self.y = signal\n",
    "    assert deriv_order > 0, 'deriv_order must be an int > 0'\n",
    "    # Compute the fixed derivative of identity (D).\n",
    "    d = np.zeros(deriv_order*2 + 1, dtype=int)\n",
    "    d[deriv_order] = 1\n",
    "    d = np.diff(d, n=deriv_order)\n",
    "    n = self.y.shape[0]\n",
    "    k = len(d)\n",
    "    s = float(smoothness_param)\n",
    "\n",
    "    # Here be dragons: essentially we're faking a big banded matrix D,\n",
    "    # doing s * D.T.dot(D) with it, then taking the upper triangular bands.\n",
    "    diag_sums = np.vstack([\n",
    "        np.pad(s*np.cumsum(d[-i:]*d[:i]), ((k-i,0),), 'constant')\n",
    "        for i in range(1, k+1)])\n",
    "    upper_bands = np.tile(diag_sums[:,-1:], n)\n",
    "    upper_bands[:,:k] = diag_sums\n",
    "    for i,ds in enumerate(diag_sums):\n",
    "      upper_bands[i,-i-1:] = ds[::-1][:i+1]\n",
    "    self.upper_bands = upper_bands\n",
    "\n",
    "  def smooth(self, w):\n",
    "    foo = self.upper_bands.copy()\n",
    "    foo[-1] += w  # last row is the diagonal\n",
    "    return solveh_banded(foo, w * self.y, overwrite_ab=True, overwrite_b=True)\n",
    "\n",
    "\n",
    "def listdirs(rootdir):\n",
    "    classes = os.listdir(rootdir)\n",
    "    subdires = []\n",
    "    files = []\n",
    "    for file in classes:\n",
    "        subdir = os.path.join(rootdir, file)\n",
    "        subdires.append(subdir)\n",
    "        if os.path.isdir(subdir):\n",
    "            files.append(listdirs(subdir)[1])\n",
    "          \n",
    "    allfiles = [item for sublist in files for item in sublist]\n",
    "    \n",
    "    return classes,subdires,allfiles\n",
    "\n",
    "\n",
    "\n",
    "def cleanfile(files):\n",
    "    ofiles = []\n",
    "    for file in files:\n",
    "        for raw in file[2]:\n",
    "            for r in raw[1]:\n",
    "                if r != []:\n",
    "                    ofiles.append(r)\n",
    "                    \n",
    "    return ofiles\n",
    "\n",
    "\n",
    "\n",
    "def fixwave(spec,wave):\n",
    "    minmin = wave.min(axis=1).min()+10\n",
    "    maxmax = wave.max(axis=1).max()-10\n",
    "    xx = np.linspace(minmin,maxmax,wave.shape[1])\n",
    "    data = []\n",
    "    \n",
    "#    spec = spec.dropna(axis=0)\n",
    "#    wave = wave.dropna(axis=0)\n",
    "    \n",
    "    for spe,wav in zip(spec.values, wave.values):\n",
    "        spl1 = make_interp_spline(sorted(wav),spe[::-1], k=3)  # type: BSpline\n",
    "        data.append(spl1(xx)[::-1])\n",
    "    \n",
    "    return pd.DataFrame(data,columns = xx[::-1],index=spec.index)\n",
    "\n",
    "def analyse_data_folders(mainfolders,clean):\n",
    "    wave = pd.DataFrame()\n",
    "    spec = pd.DataFrame()\n",
    "    \n",
    "    for mainfolder in mainfolders:\n",
    "            \n",
    "        label = mainfolder.split(\"/\")[-1]\n",
    "        classes, subdires,files = listdirs(mainfolder)\n",
    "        \n",
    "        #files = cleanfile(files)   \n",
    "        \n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        for file in files:\n",
    "            df = pd.read_csv(file,sep='\\t', header= None)\n",
    "            df.columns = ['#Wave','#Intensity']\n",
    "            df['#Intensity'] = df['#Intensity'].values - als_baseline(df['#Intensity'].values)\n",
    "            df['#Intensity'] = (df['#Intensity']-df['#Intensity'].min())/(df['#Intensity'].max()-df['#Intensity'].min())   \n",
    "            data.append(df.T)\n",
    "            \n",
    "        alldf = pd.concat(data,axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # separate wavenumber and intensity and remove nan\n",
    "        allwave = alldf[alldf.index.values=='#Wave'].iloc[:,:887]\n",
    "        allint0 =  alldf[alldf.index.values=='#Intensity'].iloc[:,:887].dropna(axis=0)\n",
    "#                         .dropna(axis=1)\n",
    "                         \n",
    "        allwave = allwave.iloc[:allint0.shape[0],:]\n",
    "                       \n",
    "    \n",
    "        \n",
    "        # use zscore to remove outliers from dataframe\n",
    "        allint  = allint0[(np.abs(stats.zscore(allint0)) < clean).all(axis=1)]\n",
    "        allint.index = [label]*allint.shape[0]\n",
    "        allwave  = allwave[(np.abs(stats.zscore(allint0.values)) < clean).all(axis=1)]\n",
    "        \n",
    "        spec = pd.concat([spec,allint])\n",
    "    #    spec.append(allint)\n",
    "        wave = pd.concat([wave,allwave])\n",
    "\n",
    "\n",
    "    return spec,wave\n",
    "    \n",
    "def plot_avg(finaldf):\n",
    "        \n",
    "    plt.figure(figsize=(9,9/1.618))\n",
    "    for cnt, (l,c) in enumerate(zip(finaldf.index.unique(),['r','g','b'])):\n",
    "        region = finaldf.index == l\n",
    "        plt.plot(finaldf.columns, finaldf.values[region].mean(axis=0)+cnt, c = c, label=l, lw=1.5)\n",
    "        plt.fill_between(finaldf.columns, finaldf.values[region].mean(axis=0)+cnt,cnt+finaldf.values[region].mean(axis=0)+finaldf.values[region].std(axis=0),color='k',alpha=0.5)\n",
    "    \n",
    "    plt.legend(loc='best', frameon=False,prop={'size': 12})\n",
    "    plt.xlabel('Raman shift (cm$^{-1}$)')\n",
    "    plt.ylabel('Relative Intensity (a.u.)')\n",
    "\n",
    "\n",
    "\n",
    "def OrganizePCAData(norm,labels,wavenumber):    \n",
    "    df_pca = pd.DataFrame(norm).reset_index(drop=True)\n",
    "    target = pd.DataFrame(labels,columns=['sample'])\n",
    "    \n",
    "    pca = PCA()\n",
    "    principalComponents = pca.fit_transform(df_pca)\n",
    "    columns = ['principal component '+str(i+1) for i in range(principalComponents.shape[1])]\n",
    "    info = ['PC '+str(i+1)+': '+str(round(pca.explained_variance_ratio_[i]*100,2))+' % \\n ' for i in range(principalComponents.shape[1])]\n",
    "    principalDf = pd.DataFrame(data = principalComponents , columns = columns)\n",
    "    df = pd.concat([principalDf, target], axis = 1)\n",
    "\n",
    "    return df,target,info,pca,wavenumber\n",
    "\n",
    "\n",
    "\n",
    "def pcafit(norm, wavenumber, labels):\n",
    "    df_pca = pd.DataFrame(norm).reset_index(drop=True)\n",
    "    target = pd.DataFrame(labels,columns=['sample'])\n",
    "    \n",
    "    pca = PCA()\n",
    "    principalComponents = pca.fit_transform(df_pca)\n",
    "    columns = ['principal component '+str(i+1) for i in range(principalComponents.shape[1])]\n",
    "\n",
    "    principalDf = pd.DataFrame(data = principalComponents , columns = columns)\n",
    "    df = pd.concat([principalDf, target], axis = 1)\n",
    "   \n",
    "    return pca,wavenumber,df\n",
    "\n",
    "\n",
    "\n",
    "def find_local_max(signal):\n",
    "    dim = signal.shape[0]\n",
    "    ans = np.zeros(dim)\n",
    "    for i in range(dim):\n",
    "        dxf = signal[i - 1] - signal[i]\n",
    "        dxb = signal[i - 1] - signal[i - 2]\n",
    "        ans[i] = 1.0 if dxf > 0 and dxb > 0 else 0.0\n",
    "    return ans > 0.5\n",
    "\n",
    "def fit_region(wavenumber,pos,tol = 10):\n",
    "    min_l = min(wavenumber.index.tolist())\n",
    "    max_l = max(wavenumber.index.tolist())\n",
    "    index = wavenumber.index[wavenumber==pos].tolist()[0]\n",
    "    index1 = index-tol\n",
    "    index2 = index+tol\n",
    "    if index1<min_l:\n",
    "        index1 = 0\n",
    "    if index2>max_l:\n",
    "        index2 = max_l\n",
    "        \n",
    "    return wavenumber[index1:index2]\n",
    "\n",
    "def linear_fit(x,a,b):\n",
    "    return a*x+b\n",
    "\n",
    "def power_law(x, a, b):\n",
    "    return a*np.power(x, b)\n",
    "\n",
    "def _1Lorentzian(x, amp, cen, wid):\n",
    "    return amp*wid**2/((x-cen)**2+wid**2)\n",
    "\n",
    "\n",
    "def get_stats(finaldf,peaks):\n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "    thick = []\n",
    "\n",
    "    for lab in finaldf.index.unique():\n",
    "        for p in peaks:\n",
    "                \n",
    "            intensity = finaldf[finaldf.index==lab]\n",
    "            \n",
    "            label.append(lab)\n",
    "            \n",
    "            thick.append(p)\n",
    "            \n",
    "            \n",
    "            data.append(np.max(intensity.values[:,(intensity.columns.values>p-20) & (intensity.columns.values<p+20)],axis=1))\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(data).dropna(axis=1)\n",
    "    label = pd.DataFrame(label)\n",
    "    thick = pd.DataFrame(thick)\n",
    "    \n",
    "    finaldf = pd.concat([df,label,thick],axis=1).reset_index(drop=True)\n",
    "    finaldf.columns = np.array(list(range(0,finaldf.shape[1]-2))+['sample','peak'])\n",
    "    finaldf = finaldf.sort_values(['peak','sample'])\n",
    "    \n",
    "    x = 'peak'\n",
    "    y = 'value'\n",
    "    hue = 'sample'\n",
    "    #    order = ['st95 mel','st95']\n",
    "    melt = pd.melt(finaldf,id_vars=[hue,x]) \n",
    "    fig,ax = plt.subplots(figsize=(9,9/1.618))\n",
    "    #    ax = sns.boxplot(x=x, y=y, data=df_melt,palette=['#00FFFF','#0000FF'])\n",
    "    ax = sns.boxplot(x = x , \n",
    "                     y = y , \n",
    "                     hue = hue ,\n",
    "                     data = melt, \n",
    "                     palette = ['r','g','b'])\n",
    "#                     palette = ['#00FFFF','#0000FF'])\n",
    "    #                 palette = ['#FF8000','#FF0000'])\n",
    "                                \n",
    "    #    ax.set_title('peak = ' + str(t) +' cm$^{-1}$')\n",
    "    \n",
    "    add_stat_annotation(ax, data = melt,\n",
    "                        x=x,\n",
    "                        y=y,\n",
    "                        hue=hue,\n",
    "                    box_pairs=[((p,\"Corynebacterium glutamicum\"),(p,\"Mycobacterium bovis BCG\")) for p in peaks]+[((p,\"Corynebacterium glutamicum\"),(p,\"Rhodococcus erythropolis\")) for p in peaks]+[((p,\"Mycobacterium bovis BCG\"),(p,\"Rhodococcus erythropolis\")) for p in peaks],\n",
    "                    test='t-test_ind', text_format='star', loc='inside', verbose=2)\n",
    "    plt.legend(loc='best', frameon=False)\n",
    "    #    ax.set_yticklabels(np.linspace(0,1,11))\n",
    "    #    ax.set_xticklabels(np.linspace(500,1600,23))\n",
    "    ax.set_xlabel('Raman shift (cm$^{-1}$)')\n",
    "    ax.set_ylabel('Rel. Intensity (a.u.)')\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "def LoadingsPlot(wavenumber,pca):\n",
    "    plt.figure(figsize=(9,9/1.618))\n",
    "    loadings = pd.DataFrame(pca.components_.T * np.sqrt(pca.explained_variance_))\n",
    "    loadings = loadings.iloc[:,:2]\n",
    "    loadings.columns = ['LPC1','LPC2']\n",
    "    plt.plot(wavenumber,savgol_filter(loadings['LPC1'],11,3),label='LPC1')\n",
    "    plt.plot(wavenumber,savgol_filter(loadings['LPC2'],11,3),ls='--',label='LPC2')\n",
    "    plt.legend(loc='best',frameon=False)\n",
    "    plt.xlabel('Raman shift (cm$^{-1}$)')\n",
    "    plt.ylabel('Loadings')\n",
    "\n",
    "  \n",
    "\n",
    "def plotload(pca,wavenumber):\n",
    "    loadings = pd.DataFrame(pca.components_.T * np.sqrt(pca.explained_variance_))\n",
    "\n",
    "    loadings = loadings.iloc[:,:2]\n",
    "    loadings.columns = ['LPC1','LPC2']\n",
    "\n",
    "\n",
    "    return loadings\n",
    "\n",
    "\n",
    "\n",
    "def smooth3(t, signal):\n",
    "    signal_i = signal[0]\n",
    "    dim = signal.shape[0]\n",
    "    U, s = get_line_laplacian_eigen(dim)\n",
    "    return matrix_exp_eigen(U, -s, t, signal)-(matrix_exp_eigen(U, -s, t, signal)[0]-signal_i)\n",
    "\n",
    "\n",
    "def plotprinc(df,loadings,wavenumber,pca,smooth):\n",
    "    \n",
    "    cycle = plt.rcParams['axes.prop_cycle'].by_key()['color'] \n",
    "    \n",
    "    colours = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        colours.append(cycle[i%len(cycle)])\n",
    "    \n",
    "\n",
    "    m1 =[1,-1,-1,1]\n",
    "    m2 = [1,1,-1,-1]\n",
    "    label = [['PC1P','PC2P'],['PC1N','PC2P'],['PC1N','PC2N'],['PC1P','PC2N']]\n",
    "        \n",
    "    fig, axs = plt.subplots(4, 4,figsize=(12,12/1.618))\n",
    "    gs = axs[1, 1].get_gridspec()  \n",
    "#    axs[2,2].remove()\n",
    "    for ax in list(chain(*axs[:2,:2])):\n",
    "        ax.remove()\n",
    "        \n",
    "    for ax in list(chain(*axs[2:,:2])):\n",
    "        ax.remove()\n",
    "        \n",
    "    for j in range(0,4):\n",
    "        for ax in axs[j,2:]:\n",
    "            ax.remove()\n",
    "#            for ax in axs[2:,j]:\n",
    "#                ax.remove()\n",
    "\n",
    "        \n",
    "    axbig = fig.add_subplot(gs[:2,:2])\n",
    "    axbig2 = fig.add_subplot(gs[2:,:2])\n",
    "    \n",
    "    axsma = fig.add_subplot(gs[0,2:])\n",
    "    axsma2 = fig.add_subplot(gs[1,2:])\n",
    "    \n",
    "    axsma3 = fig.add_subplot(gs[2,2:])\n",
    "    axsma4 = fig.add_subplot(gs[3,2:])\n",
    "    \n",
    "    combax = [axsma,axsma2,axsma3,axsma4]\n",
    " \n",
    "    axbig2.plot(wavenumber,loadings['LPC1'],label = 'LPC1')\n",
    "    axbig2.plot(wavenumber,loadings['LPC2'],label = 'LPC2')\n",
    "    axbig2.legend(loc='best', frameon=False,prop={'size': 10})  \n",
    "    \n",
    "    axbig.grid(True)\n",
    "    axbig2.grid(True)\n",
    "    \n",
    "    NUM_COLORS = len(df['sample'].unique().tolist())\n",
    "    \n",
    "    cmaps = plt.get_cmap('gist_rainbow')\n",
    "    \n",
    "    colours2 = [cmaps(1.*i/NUM_COLORS) for i in range(NUM_COLORS)]\n",
    "    \n",
    "\n",
    "    for target,colo in zip(df['sample'].unique().tolist(),colours2):\n",
    "        index = df['sample'] == target\n",
    "        axbig.plot(df['principal component 1'][index],df['principal component 2'][index],'o',label=target,c=colo)\n",
    "    \n",
    "    axbig.fill_between(np.linspace(0, df['principal component 1'].max()*1.1, 10),0,(df['principal component 2'].max()*1.1),alpha=0.2)\n",
    "    axbig.fill_between(np.linspace(df['principal component 1'].min()*1.1,0, 10),0,(df['principal component 2'].max()*1.1),alpha=0.2)\n",
    "    axbig.fill_between(np.linspace(df['principal component 1'].min()*1.1,0, 10),0,(df['principal component 2'].min()*1.1),alpha=0.2)\n",
    "    axbig.fill_between(np.linspace(0, df['principal component 1'].max()*1.1, 10),0,(df['principal component 2'].min()*1.1),alpha=0.2)\n",
    "           \n",
    "    \n",
    "    axbig.legend(loc='best', frameon=False,prop={'size': 8})\n",
    "    axbig.set_xlabel('PC1 : '+str(round(pca.explained_variance_ratio_[0]*100,2))+'%')\n",
    "    axbig.set_ylabel('PC2 : '+str(round(pca.explained_variance_ratio_[1]*100,2))+'%')\n",
    "\n",
    "    axbig2.set_xlabel('Raman shift (cm$^{-1}$)')\n",
    "    axbig2.set_ylabel('Loadings')\n",
    "    \n",
    "    maxlod = loadings.max().max()\n",
    "    \n",
    "    axbig2.fill_between(wavenumber,maxlod*1.1,alpha=0.5,color='dimgrey')\n",
    "    axbig2.fill_between(wavenumber,-maxlod*1.1,alpha=0.5,color='gainsboro')\n",
    "    \n",
    "    \n",
    "\n",
    "    x = wavenumber\n",
    "    y1 = smooth3(smooth*2,loadings['LPC1'])\n",
    "    y2 = smooth3(smooth*2,loadings['LPC2'])\n",
    "     \n",
    "    i = 0 \n",
    "\n",
    "    peaksQ = []\n",
    "    \n",
    "    for m_1,m_2 in zip(m1,m2):\n",
    "        \n",
    "#        ax[i] = fig.add_subplot()\n",
    "        \n",
    "        y1_m = y1*m_1\n",
    "        y2_m = y2*m_2\n",
    "        \n",
    "        local_max_index2 = (y1_m>0) & (find_local_max(y1_m))\n",
    "        stem2 = np.zeros(x.shape)\n",
    "        stem2[local_max_index2] = 1 \n",
    "    \n",
    "#        local_max_index3 = s2(y2,0) & (find_local_max(y2))\n",
    "        local_max_index3 = (y2_m>0) & (find_local_max(y2_m))\n",
    "        stem3 = np.zeros(x.shape)\n",
    "        stem3[local_max_index3] = 1 \n",
    "        \n",
    "#        plt.figure()\n",
    "        combax[i].plot(x[y1_m>0],y1_m[y1_m>0],'o')\n",
    "        combax[i].plot(x[y2_m>0],y2_m[y2_m>0],'o')\n",
    "        combax[i].plot(x[local_max_index2],y1_m[local_max_index2],'rx')\n",
    "        combax[i].plot(x[local_max_index3],y2_m[local_max_index3],'rx')\n",
    "        combax[i].text(x.min()*1.1,y1_m.max()*0.7,'Q'+str(i+1),color=colours[i])\n",
    "\n",
    "        combax[i].set_xlabel('Raman shift (cm$^{-1}$)')\n",
    "        combax[i].set_ylabel('L(a.u.)')\n",
    "        \n",
    "\n",
    "        \n",
    "        for wav in wavenumber[local_max_index2]:\n",
    "            reg = fit_region(wavenumber,wav,10)\n",
    "            \n",
    "            if (y1_m[reg[reg==wav].index][0] > 0):\n",
    "                try:\n",
    "                    popt_1lorentz, pcov_1lorentz = scipy.optimize.curve_fit(_1Lorentzian, \n",
    "                                                                    reg, \n",
    "                                                                    y1_m[reg.index],\n",
    "                                                                    p0=[y1_m[reg.index].max(), wav, 2/(np.pi*y1_m[reg.index].max())])\n",
    "                    pars_1 = popt_1lorentz[0:3]\n",
    "                    \n",
    "                    if (abs(pars_1[-1])>100) | (pars_1[0]<0):\n",
    "                        pass\n",
    "                    else:\n",
    "                        \n",
    "                        combax[i].plot(wavenumber,_1Lorentzian(wavenumber,*popt_1lorentz),lw=2)\n",
    "                        combax[i].fill_between(wavenumber, _1Lorentzian(wavenumber,*popt_1lorentz).min(),_1Lorentzian(wavenumber,*popt_1lorentz), alpha=0.5)\n",
    "                        peaksQ.append([df['sample'][0]]+popt_1lorentz.tolist()+['Q'+str(i+1)])\n",
    "    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                \n",
    "        for wav in wavenumber[local_max_index3]:\n",
    "            reg = fit_region(wavenumber,wav,10)\n",
    "            \n",
    "            if (y2_m[reg[reg==wav].index][0] > 0):\n",
    "    \n",
    "                try:\n",
    "                    popt_1lorentz, pcov_1lorentz = scipy.optimize.curve_fit(_1Lorentzian, \n",
    "                                                                    reg, \n",
    "                                                                    y2_m[reg.index],\n",
    "                                                                    p0=[y2_m[reg.index].max(), wav, 2/(np.pi*y2_m[reg.index].max())])\n",
    "                    \n",
    "       \n",
    "                    pars_1 = popt_1lorentz[0:3]\n",
    "                    if (abs(pars_1[-1])>100) | (pars_1[0]<0):\n",
    "                        pass\n",
    "                    else:\n",
    "\n",
    "                        combax[i].plot(wavenumber,_1Lorentzian(wavenumber,*popt_1lorentz),lw=2)\n",
    "                        combax[i].fill_between(wavenumber, _1Lorentzian(wavenumber,*popt_1lorentz).min(),\n",
    "                                         _1Lorentzian(wavenumber,*popt_1lorentz), alpha=0.5)\n",
    "\n",
    "                        peaksQ.append([df['sample'][0]]+popt_1lorentz.tolist()+['Q'+str(i+1)])\n",
    "                    \n",
    "                except:\n",
    "                    pass   \n",
    "                \n",
    "        i = i + 1\n",
    "        \n",
    "        peak = pd.DataFrame(peaksQ,columns=['label','height','center','width','importance'] )       \n",
    "         \n",
    "    peak.to_csv('loadings'+df['sample'][0]+'.csv',sep=';', index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.legend(loc='best', frameon=False,prop={'size': 8})    \n",
    "    fig.tight_layout()\n",
    "#    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def loadingpeak(finaldf):\n",
    "    \n",
    "    smooth = 7\n",
    "    norm = finaldf.values\n",
    "    wavenumber = pd.Series(finaldf.columns.values)\n",
    "    labels = finaldf.index.values\n",
    "    \n",
    "    pca,wavenumber,df= pcafit(norm, wavenumber, labels)\n",
    "    loadings = plotload(pca,wavenumber)\n",
    "    plotprinc(df,loadings,wavenumber,pca,smooth)\n",
    "    \n",
    "\n",
    "\n",
    "def LoadSOM(data,neuron):\n",
    "\n",
    "    dataval = data.values\n",
    "    \n",
    "    som = MiniSom(neuron,neuron, data.shape[1], sigma=1.5, learning_rate=.5, \n",
    "                  neighborhood_function='gaussian', random_seed=0)\n",
    "    \n",
    "    som.pca_weights_init(dataval)\n",
    "    som.train(dataval, neuron*3000, verbose=True)  # random training\n",
    "\n",
    "    return som \n",
    "\n",
    "\n",
    "def PlotAvgSpec(data):\n",
    "    classes = np.unique(data.index)\n",
    "    colours = ['r','g','b']\n",
    "    \n",
    "    plt.figure(figsize=(9,9/1.618))\n",
    "    for cnt, (lab,col) in enumerate(zip(classes,colours)):\n",
    "        index = lab == data.index\n",
    "        xx = data.columns\n",
    "        yy = data[index].values\n",
    "        plt.plot( xx , yy.mean(axis=0)+cnt , label = lab,color=matplotlib.colors.to_rgba(col,alpha=1),lw=2)\n",
    "    \n",
    "        for cnt2,y in enumerate(yy):\n",
    "\n",
    "            yavg2 = (y-np.min(np.mean(yy,axis=0)))/(np.max(np.mean(yy,axis=0))-np.min(np.mean(yy,axis=0)))\n",
    "            plt.plot(xx, cnt + yavg2, color = matplotlib.colors.to_rgba(col,alpha=0.01))\n",
    "        \n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.xlabel('Raman shift (cm$^{-1}$)')\n",
    "    plt.ylabel('Relative Intensity (a.u.)')\n",
    "    plt.legend(by_label.values(), by_label.keys(),loc='best', frameon=False,prop={'size': 12})\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def ColorHexBins(plot_points,cla_col,wy,wx,alpha):\n",
    "    final_c = []\n",
    "    color_hex = []\n",
    "    for pp,cc in zip(plot_points,cla_col):\n",
    "        color_hex.append([pp[0],pp[1],cc[0],cc[1]])\n",
    "    \n",
    "    df_color_hex = pd.DataFrame(color_hex,columns=['pos x','pos y','label','color'])\n",
    "    \n",
    "    uni = (wx,wy)\n",
    "    index1 =  df_color_hex['pos x']==uni[0]\n",
    "    index2 =  df_color_hex['pos y']==uni[1]\n",
    "    index = index1 & index2\n",
    "\n",
    "    df_clean = df_color_hex[index].reset_index(drop=True) \n",
    "    \n",
    "    counts = []\n",
    "    \n",
    "    for lab in df_clean['label'].unique():\n",
    "        index3 = df_clean['label'] == lab\n",
    "        counts.append([sum(index3),lab])\n",
    "\n",
    "        \n",
    "    counts = pd.DataFrame(counts,columns=['counts','label'])\n",
    "    counts = counts.sort_values(by='counts')\n",
    "    \n",
    "    if counts.empty or counts['counts'].iloc[-1] == 0:\n",
    "        final_c.append((0.5,0.5,0.5,1))\n",
    "    else:\n",
    "        index4 =  df_color_hex['pos x']==uni[0]\n",
    "        index5 =  df_color_hex['pos y']==uni[1]\n",
    "        index6 = df_color_hex['label']==counts['label'].iloc[-1]\n",
    "        index7 = index4 & index5 & index6\n",
    "        \n",
    "        final_c.append(df_color_hex[index7]['color'].unique()[0])\n",
    "\n",
    "    return matplotlib.colors.to_rgba(final_c[0],alpha=alpha)\n",
    "        \n",
    "\n",
    "\n",
    "def HexagonaSOMPlot(som,data,neuron):\n",
    "    \n",
    "    colours = ['r','g','b']\n",
    "    \n",
    "    columns = list(data.columns)  \n",
    "#    activation = pd.DataFrame([[a[0],a[1], b[0]] for a,b in som.win_map( data.values).items()])\n",
    "    somatrix = pd.DataFrame([[a[0],a[1],b.most_common()[0][0],b.most_common()[0][1]] for a,b in som.labels_map(data.values,data.index.values).items()],columns=['row','col','label','counts']).sort_values(by=['row','col']).reset_index(drop=True)\n",
    "\n",
    "    array = []\n",
    "\n",
    "    for i in range(neuron):\n",
    "#        counter = 0\n",
    "        for j in range(neuron):\n",
    "            \n",
    "#            for soma in somatrix.values:\n",
    "                \n",
    "#                if (soma[0] == i) and (soma[1] == j):\n",
    "            if np.any((somatrix['row']==i) & (somatrix['col']==j)):\n",
    "                array.append(somatrix[(somatrix['row']==i) & (somatrix['col']==j)].values[0])\n",
    "#                array.append([i,j,soma[2],soma[3]])\n",
    "#                counter = 1\n",
    "            else:\n",
    "                \n",
    "#            if counter == 0:\n",
    "                array.append([i,j, np.nan, np.nan])\n",
    "        \n",
    "    somatrix = pd.DataFrame(array,columns=somatrix.columns)\n",
    "                \n",
    "    \n",
    "    target = list(data.index.values)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(target)\n",
    "\n",
    "    \n",
    "    classes = np.unique(data.index)\n",
    "    \n",
    "   \n",
    "    dataval = data.values\n",
    "    xx, yy = som.get_euclidean_coordinates()\n",
    "    umatrix = som.distance_map()\n",
    "    weights = som.get_weights()\n",
    "    \n",
    "    \n",
    "    #code to align the hexagonals\n",
    "    a = []\n",
    "    \n",
    "    for i in range(xx.shape[0]):\n",
    "        b = []\n",
    "        for j in range(xx.shape[1]):   \n",
    "            if j % 2 == 0:\n",
    "                b.append(0)\n",
    "            else:\n",
    "                b.append(0.5)\n",
    "        a.append(b)\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "       \n",
    "    #enumerate gives you the count (cnt) and the interation value (x) represents each row\n",
    "    cla_col = []\n",
    "            \n",
    "    plot_points = []\n",
    "    \n",
    "    maxcol = []\n",
    "    for c , color in zip(classes,colours):\n",
    "        idx_target = data.index.values == c\n",
    "        \n",
    "        \n",
    "        maxcol.append([c,somatrix[somatrix['label']==c]['counts'].max()])\n",
    "        \n",
    "        for cnt, x in enumerate(dataval[idx_target]):\n",
    "            # getting the winner\n",
    "            w = som.winner(x)\n",
    "            # place a marker on the winning position for the sample xx\n",
    "            wx, wy = som.convert_map_to_euclidean(w) \n",
    "            \n",
    "            if wy%2 == 0:\n",
    "                wx = wx\n",
    "            else:\n",
    "                wx = wx+0.5\n",
    "            \n",
    "            wy = wy * np.sqrt(3) / 2\n",
    "            \n",
    "            plot_points.append([wx,wy])\n",
    "            cla_col.append([c,color])\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "     # iteratively add hexagons\n",
    "#    plt.figure()\n",
    "         \n",
    "    fig2 = plt.figure()\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    \n",
    "    for label,color in zip(classes,colours):         \n",
    "        index = somatrix['label'] == label\n",
    "        ax2.plot(columns,\n",
    "                 np.mean(weights.reshape(weights.shape[0]*weights.shape[1],weights.shape[2])[index],axis=0),\n",
    "                 c= color,\n",
    "                 zorder=1000,\n",
    "                 linewidth = 2)\n",
    "\n",
    "    \n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            \n",
    "            if somatrix['label'][i*weights.shape[0]+j] is np.nan:\n",
    "                wy = yy[(i, j)] * np.sqrt(3) / 2\n",
    "                wx = xx[(i, j)] + pd.DataFrame(a).values[(i,j)]\n",
    "                hexa = RegularPolygon((wx, wy), \n",
    "                                         numVertices=6, \n",
    "                                         radius=.95 / np.sqrt(3),\n",
    "                                         facecolor=ColorHexBins(plot_points,cla_col,wy,wx,0),\n",
    "                                         linewidth=1,\n",
    "                                         edgecolor= (0,0,0,1))\n",
    "        \n",
    "                ax.add_patch(hexa)\n",
    "            \n",
    "            else:\n",
    "                    \n",
    "                wy = yy[(i, j)] * np.sqrt(3) / 2\n",
    "                wx = xx[(i, j)] + pd.DataFrame(a).values[(i,j)]\n",
    "                ax2.plot(columns,\n",
    "                         weights[i][j], \n",
    "                         color = matplotlib.colors.to_rgba([b for a,b in zip(classes,colours) if a == somatrix['label'][i*weights.shape[0]+j]][0],alpha=0.05),\n",
    "                label = somatrix['label'][i*weights.shape[0]+j])\n",
    "    \n",
    "                for col in maxcol:\n",
    "                    lab,con = col\n",
    "                    if somatrix['label'].values[i*weights.shape[0]+j] == lab:\n",
    "                        alpha = somatrix['counts'].values[i*weights.shape[0]+j]/con\n",
    "                        \n",
    "                        hexa = RegularPolygon((wx, wy), \n",
    "                                             numVertices=6, \n",
    "                                             radius=.95 / np.sqrt(3),\n",
    "                                             facecolor=ColorHexBins(plot_points,cla_col,wy,wx,alpha),\n",
    "                                             linewidth=1,\n",
    "                                             edgecolor= (0,0,0,1))\n",
    "            \n",
    "                        ax.add_patch(hexa)\n",
    "            \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    leg = ax2.legend(by_label.values(), by_label.keys(),loc='best', frameon=False)\n",
    "    \n",
    "    for lh in leg.legendHandles: \n",
    "        lh.set_alpha(1)\n",
    "    \n",
    "    ax2.set_xlabel('Raman shift (cm$^{-1}$)')\n",
    "    ax2.set_ylabel('Activations (a.u.)')\n",
    "    \n",
    "    \n",
    "    \n",
    "    xrange = np.arange(weights.shape[0])\n",
    "    yrange = np.arange(weights.shape[1])\n",
    "    ax.set_xlim(xrange.min()-1, xrange.max()+1)\n",
    "    ax.set_ylim(yrange.min() * np.sqrt(3) / 2-1, yrange.max()* np.sqrt(3) / 2+1)\n",
    "\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3447aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakfinder(finaldf):\n",
    "\n",
    "    peak_vector = []\n",
    "    err = []\n",
    "    \n",
    "        \n",
    "    for label in finaldf.index.unique():\n",
    "\n",
    "        wavenumber = pd.Series(finaldf.columns.values)\n",
    "        intensity = finaldf[finaldf.index==label]\n",
    "        avg = intensity.mean().values\n",
    "        avg = smooth2(7,  avg)\n",
    "        avg = (avg - avg.min())/(avg.max()-avg.min())\n",
    "       \n",
    "       \n",
    "        local_max_index = find_local_max(avg)\n",
    "    \n",
    "        stem = np.zeros(wavenumber.shape)\n",
    "        stem[local_max_index] = 1  \n",
    "        \n",
    "        lorentz = []\n",
    "\n",
    "        \n",
    "        for wav in wavenumber[local_max_index]:\n",
    "    \n",
    "            reg = fit_region(wavenumber,wav,10)\n",
    "            \n",
    "            try:\n",
    "                popt_1lorentz, pcov_1lorentz = scipy.optimize.curve_fit(_1Lorentzian, \n",
    "                                                                reg, \n",
    "                                                                avg[reg.index],\n",
    "                                                                p0=[avg[reg.index].max(), wav,  2/(np.pi*avg[reg.index].max())])\n",
    "                \n",
    "                perr_1lorentz = np.sqrt(np.diag(pcov_1lorentz))\n",
    "        \n",
    "                pars_1 = popt_1lorentz[0:3]\n",
    "                \n",
    "                if (abs(pars_1[-1])>100) | (pars_1[0]<0):\n",
    "                    pass\n",
    "                else:\n",
    "                    \n",
    "\n",
    "        \n",
    "                    lorentz.append(_1Lorentzian(wavenumber,*popt_1lorentz))\n",
    "                    peak_vector.append([label]+popt_1lorentz.tolist()+['major'])\n",
    "                    err.append(perr_1lorentz[0])\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "     \n",
    "    for peak, e in zip(peak_vector,err):\n",
    "        peak.append(e)\n",
    "    \n",
    "    peak = pd.DataFrame(peak_vector,columns=['label','height','center','width','importance','err'])\n",
    "        \n",
    "    return peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456cc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCAPlot2D(df,target,info):  \n",
    "    \n",
    "    fig = plt.figure(figsize=(9,9/1.618))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    plt.xlabel(str(info[0]))\n",
    "    plt.ylabel(str(info[1]))\n",
    "    \n",
    "    \n",
    "    NUM_COLORS = len(list(np.unique(target)))  \n",
    "    cmaps = plt.get_cmap('gist_rainbow')\n",
    "    colours = [cmaps(1.*i/NUM_COLORS) for i in range(NUM_COLORS)]\n",
    "        \n",
    "    for label,color in zip(list(np.unique(target)),colours):\n",
    "        indicesToKeep = df['sample'] == label\n",
    "        \n",
    "        if df.loc[indicesToKeep].shape[0] < 2:\n",
    "            \n",
    "            new_x = df.loc[indicesToKeep, 'principal component 1']\n",
    "            new_y = df.loc[indicesToKeep, 'principal component 2']\n",
    "            ax.scatter(new_x, new_y, s =100,alpha=1,label=label,marker='x',color = color)\n",
    "            handles, labels = plt.gca().get_legend_handles_labels()\n",
    "            by_label = OrderedDict(zip(labels, handles))\n",
    "            plt.legend(loc='best',frameon=False)\n",
    "            \n",
    "        else:\n",
    "                \n",
    "          \n",
    "            gmm = GaussianMixture(n_components=1).fit(pd.concat([df.loc[indicesToKeep, 'principal component 1']\n",
    "                       , df.loc[indicesToKeep, 'principal component 2']],axis=1).values)\n",
    "        \n",
    "        \n",
    "           \n",
    "            for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "#                    print(pos)\n",
    "#                    print(covar)\n",
    "                \n",
    "                \n",
    "                if covar.shape == (2, 2):\n",
    "                    U, s, Vt = np.linalg.svd(covar)\n",
    "                    angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "                    width, height = 2 * np.sqrt(s)\n",
    "                else:\n",
    "                    angle = 0\n",
    "                    width, height = 2 * np.sqrt(covar)\n",
    "                    \n",
    "            #draw the 2sigma region\n",
    "                ax.add_patch(Ellipse(pos,2*width,2*height,angle,alpha=0.3,color = color))\n",
    "        \n",
    "                \n",
    "                new_x = df.loc[indicesToKeep, 'principal component 1']\n",
    "                new_y = df.loc[indicesToKeep, 'principal component 2']\n",
    "                \n",
    "            #    ax.scatter(new_x, new_y, c = color , s =100,alpha=1,label=target,marker='x')\n",
    "                \n",
    "                range1s = (((new_x < pos[0]+np.sqrt(width/2)) & (new_x > pos[0]-np.sqrt(width/2))) | \n",
    "                        ((new_y < pos[1]+np.sqrt(height/2)) & (new_y > pos[1]-np.sqrt(height/2))))\n",
    "                ax.scatter(new_x[range1s], new_y[range1s], s =100,alpha=1,label=label,marker='x',color = color)\n",
    "            \n",
    "            #    plot_gmm(gmm)\n",
    "            \n",
    "                handles, labels = plt.gca().get_legend_handles_labels()\n",
    "                by_label = OrderedDict(zip(labels, handles))\n",
    "                plt.legend(loc='best',frameon=False)\n",
    "                \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae387af1",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5091f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from files\n",
    "spec,wave = analyse_data_folders(mainfolders,clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5729f490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>877</th>\n",
       "      <th>878</th>\n",
       "      <th>879</th>\n",
       "      <th>880</th>\n",
       "      <th>881</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>884</th>\n",
       "      <th>885</th>\n",
       "      <th>886</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Corynebacterium glutamicum</th>\n",
       "      <td>0.227653</td>\n",
       "      <td>0.227494</td>\n",
       "      <td>0.223579</td>\n",
       "      <td>0.214980</td>\n",
       "      <td>0.227035</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.219030</td>\n",
       "      <td>0.215026</td>\n",
       "      <td>0.195523</td>\n",
       "      <td>0.211218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430927</td>\n",
       "      <td>0.428915</td>\n",
       "      <td>0.400193</td>\n",
       "      <td>0.331481</td>\n",
       "      <td>0.297431</td>\n",
       "      <td>0.212763</td>\n",
       "      <td>0.173664</td>\n",
       "      <td>0.133377</td>\n",
       "      <td>0.070725</td>\n",
       "      <td>0.048149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corynebacterium glutamicum</th>\n",
       "      <td>0.215113</td>\n",
       "      <td>0.215774</td>\n",
       "      <td>0.213217</td>\n",
       "      <td>0.205258</td>\n",
       "      <td>0.218897</td>\n",
       "      <td>0.210378</td>\n",
       "      <td>0.211386</td>\n",
       "      <td>0.207202</td>\n",
       "      <td>0.187301</td>\n",
       "      <td>0.204562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228752</td>\n",
       "      <td>0.249097</td>\n",
       "      <td>0.244289</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.195867</td>\n",
       "      <td>0.141188</td>\n",
       "      <td>0.138251</td>\n",
       "      <td>0.137446</td>\n",
       "      <td>0.116980</td>\n",
       "      <td>0.143007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corynebacterium glutamicum</th>\n",
       "      <td>0.227842</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>0.223712</td>\n",
       "      <td>0.215094</td>\n",
       "      <td>0.227110</td>\n",
       "      <td>0.218647</td>\n",
       "      <td>0.219009</td>\n",
       "      <td>0.214930</td>\n",
       "      <td>0.195431</td>\n",
       "      <td>0.211156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429548</td>\n",
       "      <td>0.427670</td>\n",
       "      <td>0.399110</td>\n",
       "      <td>0.330512</td>\n",
       "      <td>0.296687</td>\n",
       "      <td>0.212218</td>\n",
       "      <td>0.173361</td>\n",
       "      <td>0.133343</td>\n",
       "      <td>0.070989</td>\n",
       "      <td>0.048778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corynebacterium glutamicum</th>\n",
       "      <td>0.226069</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.220987</td>\n",
       "      <td>0.212507</td>\n",
       "      <td>0.228932</td>\n",
       "      <td>0.215696</td>\n",
       "      <td>0.219596</td>\n",
       "      <td>0.214280</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>0.215024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233244</td>\n",
       "      <td>0.250619</td>\n",
       "      <td>0.244987</td>\n",
       "      <td>0.204037</td>\n",
       "      <td>0.199275</td>\n",
       "      <td>0.143836</td>\n",
       "      <td>0.142151</td>\n",
       "      <td>0.139398</td>\n",
       "      <td>0.118353</td>\n",
       "      <td>0.143631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corynebacterium glutamicum</th>\n",
       "      <td>0.238383</td>\n",
       "      <td>0.226446</td>\n",
       "      <td>0.228642</td>\n",
       "      <td>0.218920</td>\n",
       "      <td>0.236266</td>\n",
       "      <td>0.218702</td>\n",
       "      <td>0.224265</td>\n",
       "      <td>0.217446</td>\n",
       "      <td>0.199851</td>\n",
       "      <td>0.218921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238019</td>\n",
       "      <td>0.253590</td>\n",
       "      <td>0.247277</td>\n",
       "      <td>0.208225</td>\n",
       "      <td>0.202940</td>\n",
       "      <td>0.146026</td>\n",
       "      <td>0.145295</td>\n",
       "      <td>0.141102</td>\n",
       "      <td>0.119279</td>\n",
       "      <td>0.144374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 887 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0         1         2         3         4    \\\n",
       "Corynebacterium glutamicum  0.227653  0.227494  0.223579  0.214980  0.227035   \n",
       "Corynebacterium glutamicum  0.215113  0.215774  0.213217  0.205258  0.218897   \n",
       "Corynebacterium glutamicum  0.227842  0.227642  0.223712  0.215094  0.227110   \n",
       "Corynebacterium glutamicum  0.226069  0.220200  0.220987  0.212507  0.228932   \n",
       "Corynebacterium glutamicum  0.238383  0.226446  0.228642  0.218920  0.236266   \n",
       "\n",
       "                                 5         6         7         8         9    \\\n",
       "Corynebacterium glutamicum  0.218605  0.219030  0.215026  0.195523  0.211218   \n",
       "Corynebacterium glutamicum  0.210378  0.211386  0.207202  0.187301  0.204562   \n",
       "Corynebacterium glutamicum  0.218647  0.219009  0.214930  0.195431  0.211156   \n",
       "Corynebacterium glutamicum  0.215696  0.219596  0.214280  0.196440  0.215024   \n",
       "Corynebacterium glutamicum  0.218702  0.224265  0.217446  0.199851  0.218921   \n",
       "\n",
       "                            ...       877       878       879       880  \\\n",
       "Corynebacterium glutamicum  ...  0.430927  0.428915  0.400193  0.331481   \n",
       "Corynebacterium glutamicum  ...  0.228752  0.249097  0.244289  0.200097   \n",
       "Corynebacterium glutamicum  ...  0.429548  0.427670  0.399110  0.330512   \n",
       "Corynebacterium glutamicum  ...  0.233244  0.250619  0.244987  0.204037   \n",
       "Corynebacterium glutamicum  ...  0.238019  0.253590  0.247277  0.208225   \n",
       "\n",
       "                                 881       882       883       884       885  \\\n",
       "Corynebacterium glutamicum  0.297431  0.212763  0.173664  0.133377  0.070725   \n",
       "Corynebacterium glutamicum  0.195867  0.141188  0.138251  0.137446  0.116980   \n",
       "Corynebacterium glutamicum  0.296687  0.212218  0.173361  0.133343  0.070989   \n",
       "Corynebacterium glutamicum  0.199275  0.143836  0.142151  0.139398  0.118353   \n",
       "Corynebacterium glutamicum  0.202940  0.146026  0.145295  0.141102  0.119279   \n",
       "\n",
       "                                 886  \n",
       "Corynebacterium glutamicum  0.048149  \n",
       "Corynebacterium glutamicum  0.143007  \n",
       "Corynebacterium glutamicum  0.048778  \n",
       "Corynebacterium glutamicum  0.143631  \n",
       "Corynebacterium glutamicum  0.144374  \n",
       "\n",
       "[5 rows x 887 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The way the data has been organized to optimize the memory allocation has been: the index as the sample label\n",
    "# i.e. the name of the folder. and the spectra in each row. At the end of the complete processing the header\n",
    "# will have the wavenumber\n",
    "spec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d998df7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>877</th>\n",
       "      <th>878</th>\n",
       "      <th>879</th>\n",
       "      <th>880</th>\n",
       "      <th>881</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>884</th>\n",
       "      <th>885</th>\n",
       "      <th>886</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#Wave</th>\n",
       "      <td>1713.643555</td>\n",
       "      <td>1712.668945</td>\n",
       "      <td>1711.693359</td>\n",
       "      <td>1710.71875</td>\n",
       "      <td>1709.743164</td>\n",
       "      <td>1708.767578</td>\n",
       "      <td>1707.791992</td>\n",
       "      <td>1706.81543</td>\n",
       "      <td>1705.839844</td>\n",
       "      <td>1704.863281</td>\n",
       "      <td>...</td>\n",
       "      <td>770.880859</td>\n",
       "      <td>769.695313</td>\n",
       "      <td>768.508789</td>\n",
       "      <td>767.322266</td>\n",
       "      <td>766.134766</td>\n",
       "      <td>764.947266</td>\n",
       "      <td>763.759766</td>\n",
       "      <td>762.572266</td>\n",
       "      <td>761.383789</td>\n",
       "      <td>760.195313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Wave</th>\n",
       "      <td>1713.643555</td>\n",
       "      <td>1712.668945</td>\n",
       "      <td>1711.693359</td>\n",
       "      <td>1710.71875</td>\n",
       "      <td>1709.743164</td>\n",
       "      <td>1708.767578</td>\n",
       "      <td>1707.791992</td>\n",
       "      <td>1706.81543</td>\n",
       "      <td>1705.839844</td>\n",
       "      <td>1704.863281</td>\n",
       "      <td>...</td>\n",
       "      <td>770.880859</td>\n",
       "      <td>769.695313</td>\n",
       "      <td>768.508789</td>\n",
       "      <td>767.322266</td>\n",
       "      <td>766.134766</td>\n",
       "      <td>764.947266</td>\n",
       "      <td>763.759766</td>\n",
       "      <td>762.572266</td>\n",
       "      <td>761.383789</td>\n",
       "      <td>760.195313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Wave</th>\n",
       "      <td>1713.643555</td>\n",
       "      <td>1712.668945</td>\n",
       "      <td>1711.693359</td>\n",
       "      <td>1710.71875</td>\n",
       "      <td>1709.743164</td>\n",
       "      <td>1708.767578</td>\n",
       "      <td>1707.791992</td>\n",
       "      <td>1706.81543</td>\n",
       "      <td>1705.839844</td>\n",
       "      <td>1704.863281</td>\n",
       "      <td>...</td>\n",
       "      <td>770.880859</td>\n",
       "      <td>769.695313</td>\n",
       "      <td>768.508789</td>\n",
       "      <td>767.322266</td>\n",
       "      <td>766.134766</td>\n",
       "      <td>764.947266</td>\n",
       "      <td>763.759766</td>\n",
       "      <td>762.572266</td>\n",
       "      <td>761.383789</td>\n",
       "      <td>760.195313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Wave</th>\n",
       "      <td>1713.643555</td>\n",
       "      <td>1712.668945</td>\n",
       "      <td>1711.693359</td>\n",
       "      <td>1710.71875</td>\n",
       "      <td>1709.743164</td>\n",
       "      <td>1708.767578</td>\n",
       "      <td>1707.791992</td>\n",
       "      <td>1706.81543</td>\n",
       "      <td>1705.839844</td>\n",
       "      <td>1704.863281</td>\n",
       "      <td>...</td>\n",
       "      <td>770.880859</td>\n",
       "      <td>769.695313</td>\n",
       "      <td>768.508789</td>\n",
       "      <td>767.322266</td>\n",
       "      <td>766.134766</td>\n",
       "      <td>764.947266</td>\n",
       "      <td>763.759766</td>\n",
       "      <td>762.572266</td>\n",
       "      <td>761.383789</td>\n",
       "      <td>760.195313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Wave</th>\n",
       "      <td>1713.643555</td>\n",
       "      <td>1712.668945</td>\n",
       "      <td>1711.693359</td>\n",
       "      <td>1710.71875</td>\n",
       "      <td>1709.743164</td>\n",
       "      <td>1708.767578</td>\n",
       "      <td>1707.791992</td>\n",
       "      <td>1706.81543</td>\n",
       "      <td>1705.839844</td>\n",
       "      <td>1704.863281</td>\n",
       "      <td>...</td>\n",
       "      <td>770.880859</td>\n",
       "      <td>769.695313</td>\n",
       "      <td>768.508789</td>\n",
       "      <td>767.322266</td>\n",
       "      <td>766.134766</td>\n",
       "      <td>764.947266</td>\n",
       "      <td>763.759766</td>\n",
       "      <td>762.572266</td>\n",
       "      <td>761.383789</td>\n",
       "      <td>760.195313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 887 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1            2           3            4    \\\n",
       "#Wave  1713.643555  1712.668945  1711.693359  1710.71875  1709.743164   \n",
       "#Wave  1713.643555  1712.668945  1711.693359  1710.71875  1709.743164   \n",
       "#Wave  1713.643555  1712.668945  1711.693359  1710.71875  1709.743164   \n",
       "#Wave  1713.643555  1712.668945  1711.693359  1710.71875  1709.743164   \n",
       "#Wave  1713.643555  1712.668945  1711.693359  1710.71875  1709.743164   \n",
       "\n",
       "               5            6           7            8            9    ...  \\\n",
       "#Wave  1708.767578  1707.791992  1706.81543  1705.839844  1704.863281  ...   \n",
       "#Wave  1708.767578  1707.791992  1706.81543  1705.839844  1704.863281  ...   \n",
       "#Wave  1708.767578  1707.791992  1706.81543  1705.839844  1704.863281  ...   \n",
       "#Wave  1708.767578  1707.791992  1706.81543  1705.839844  1704.863281  ...   \n",
       "#Wave  1708.767578  1707.791992  1706.81543  1705.839844  1704.863281  ...   \n",
       "\n",
       "              877         878         879         880         881         882  \\\n",
       "#Wave  770.880859  769.695313  768.508789  767.322266  766.134766  764.947266   \n",
       "#Wave  770.880859  769.695313  768.508789  767.322266  766.134766  764.947266   \n",
       "#Wave  770.880859  769.695313  768.508789  767.322266  766.134766  764.947266   \n",
       "#Wave  770.880859  769.695313  768.508789  767.322266  766.134766  764.947266   \n",
       "#Wave  770.880859  769.695313  768.508789  767.322266  766.134766  764.947266   \n",
       "\n",
       "              883         884         885         886  \n",
       "#Wave  763.759766  762.572266  761.383789  760.195313  \n",
       "#Wave  763.759766  762.572266  761.383789  760.195313  \n",
       "#Wave  763.759766  762.572266  761.383789  760.195313  \n",
       "#Wave  763.759766  762.572266  761.383789  760.195313  \n",
       "#Wave  763.759766  762.572266  761.383789  760.195313  \n",
       "\n",
       "[5 rows x 887 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One thing to not related to the wavelength values is that, depending on the day of usage of the machine,\n",
    "# the values will be sligtly shifted +/-0.01 cm-1. Still to make a proper analysis we need to interpolate them\n",
    "# to the same wavelenght values.\n",
    "wave.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20276e4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114338/1294612654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fix wavenumber among different datasets, ie, unify wavenumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinaldf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixwave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfinaldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_114338/2794840998.py\u001b[0m in \u001b[0;36mfixwave\u001b[0;34m(spec, wave)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspl1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalyse_data_folders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmainfolders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[1;32m    695\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                         \u001b[0;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fix wavenumber among different datasets, ie, unify wavenumber\n",
    "finaldf = fixwave(spec,wave)\n",
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550915c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot average\n",
    "plot_avg(finaldf)\n",
    "PlotAvgSpec(finaldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a8f18",
   "metadata": {},
   "source": [
    "Note to save these images go to File > Download as > Markdown (.md). Then open .svg files in Inkscape to manually edit them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ebd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA analysis\n",
    "#pca,wavenumber,df = pcafit(finaldf.values,finaldf.columns,finaldf.index)\n",
    "df,target,info,pca,wavenumber = OrganizePCAData(finaldf.values, finaldf.index, finaldf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAPlot2D(df,df['sample'],info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae09db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.prop_cycle'] = plt.rcParamsDefault['axes.prop_cycle']\n",
    "LoadingsPlot(wavenumber,pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.prop_cycle'] = plt.rcParamsDefault['axes.prop_cycle']\n",
    "loadingpeak(finaldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303dd0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most important peaks using a inteligent lorentzina fit\n",
    "#RUN FIRST THIS CODE AND THEN COMMENT IT AFTER THE .CSV FILE IS GENERATED!!\n",
    "peaks = peakfinder(finaldf)\n",
    "peaks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment next line to save the peak file. Manually check the file and write your costum peak list\n",
    "#peaks.to_csv(savefolder+'test.csv')\n",
    "\n",
    "#Example of a peaks list were manually selected from the csv file created by the peakfinder function. write the peaks\n",
    "# of interest that you found inside the brakets, uncomment the next line and run the 'get stats' script to make the\n",
    "# histogram plot\n",
    "peaks = [780, 850, 1000, 1155, 1210, 1335, 1450, 1525, 1575, 1610, 1660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script will run the different peaks in the previous peak list and chech the intensity with respect to all the\n",
    "# different measurements and samples and thus buiding a statistical significance from the intensity of the peak.\n",
    "# test='t-test_ind'\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colours)\n",
    "get_stats(finaldf,peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOM section insert the number of hexagon sides that you want (square shape)\n",
    "som = LoadSOM(finaldf,neuron)\n",
    "HexagonaSOMPlot(som,finaldf,neuron)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
